{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Machine Learning — Project1**\n",
    "刘蔚璁 10225501443 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **实验背景**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次数据使用的是 UCI 存储库提供的蘑菇数据集（Mushroom Dataset），创建于 1981 年，是一个生物学领域的多变量二分类数据集。该数据集包含 8124 个样本和 22 个分类特征，描述了伞菌科和口蘑科蘑菇的物理特性（如蘑菇帽形状、颜色、气味等），目标变量是蘑菇的可食用性（“可食用”或“有毒”）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "具体特征如下表所示：\n",
    "\n",
    "| 特征名                     | 英文含义                                        | 中文含义                              |\n",
    "|----------------------------|------------------------------------------------|---------------------------------------|\n",
    "| cap-shape                 | Shape of the cap                               | 蘑菇帽的形状                         |\n",
    "| cap-surface               | Surface texture of the cap                    | 蘑菇帽的表面质地                     |\n",
    "| cap-color                 | Color of the cap                              | 蘑菇帽的颜色                         |\n",
    "| bruises                   | Whether the mushroom bruises                  | 是否有瘀伤                           |\n",
    "| odor                      | Smell of the mushroom                         | 蘑菇的气味                           |\n",
    "| gill-attachment           | Attachment type of the gills                  | 菌褶的附着类型                       |\n",
    "| gill-spacing              | Spacing between the gills                     | 菌褶之间的间距                       |\n",
    "| gill-size                 | Size of the gills                             | 菌褶的大小                           |\n",
    "| gill-color                | Color of the gills                            | 菌褶的颜色                           |\n",
    "| stalk-shape               | Shape of the stalk                            | 茎的形状                             |\n",
    "| stalk-root                | Root type of the stalk                        | 茎的根部类型                         |\n",
    "| stalk-surface-above-ring  | Surface texture of stalk above the ring       | 茎环以上的表面质地                   |\n",
    "| stalk-surface-below-ring  | Surface texture of stalk below the ring       | 茎环以下的表面质地                   |\n",
    "| stalk-color-above-ring    | Color of the stalk above the ring             | 茎环以上的颜色                       |\n",
    "| stalk-color-below-ring    | Color of the stalk below the ring             | 茎环以下的颜色                       |\n",
    "| veil-type                 | Type of the veil                              | 菌幕的类型                           |\n",
    "| veil-color                | Color of the veil                             | 菌幕的颜色                           |\n",
    "| ring-number               | Number of rings on the stalk                  | 茎上的环数量                         |\n",
    "| ring-type                 | Type of rings on the stalk                    | 茎环的类型                           |\n",
    "| spore-print-color         | Color of the spore print                      | 孢子印的颜色                         |\n",
    "| population                | Size of the mushroom population               | 蘑菇种群的大小                       |\n",
    "| habitat\t                | Natural habitat of the mushroom               | 蘑菇的自然栖息地                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **实验目标**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分别使用逻辑回归、决策树和 SVM 对蘑菇数据集进行分类，比较三种方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **实验前的准备**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入所需要的 Python 安装包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置随机种子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 622"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mushroom = fetch_ucirepo(id=73) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = mushroom.data.features \n",
    "y = mushroom.data.targets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看数据集基本信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uci_id': 73,\n",
       " 'name': 'Mushroom',\n",
       " 'repository_url': 'https://archive.ics.uci.edu/dataset/73/mushroom',\n",
       " 'data_url': 'https://archive.ics.uci.edu/static/public/73/data.csv',\n",
       " 'abstract': 'From Audobon Society Field Guide; mushrooms described in terms of physical characteristics; classification: poisonous or edible',\n",
       " 'area': 'Biology',\n",
       " 'tasks': ['Classification'],\n",
       " 'characteristics': ['Multivariate'],\n",
       " 'num_instances': 8124,\n",
       " 'num_features': 22,\n",
       " 'feature_types': ['Categorical'],\n",
       " 'demographics': [],\n",
       " 'target_col': ['poisonous'],\n",
       " 'index_col': None,\n",
       " 'has_missing_values': 'yes',\n",
       " 'missing_values_symbol': 'NaN',\n",
       " 'year_of_dataset_creation': 1981,\n",
       " 'last_updated': 'Thu Aug 10 2023',\n",
       " 'dataset_doi': '10.24432/C5959T',\n",
       " 'creators': [],\n",
       " 'intro_paper': None,\n",
       " 'additional_info': {'summary': \"This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family (pp. 500-525).  Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended.  This latter class was combined with the poisonous one.  The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like ``leaflets three, let it be'' for Poisonous Oak and Ivy.\",\n",
       "  'purpose': None,\n",
       "  'funded_by': None,\n",
       "  'instances_represent': None,\n",
       "  'recommended_data_splits': None,\n",
       "  'sensitive_data': None,\n",
       "  'preprocessing_description': None,\n",
       "  'variable_info': '     1. cap-shape:                bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\\r\\n     2. cap-surface:              fibrous=f,grooves=g,scaly=y,smooth=s\\r\\n     3. cap-color:                brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y\\r\\n     4. bruises?:                 bruises=t,no=f\\r\\n     5. odor:                     almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\\r\\n     6. gill-attachment:          attached=a,descending=d,free=f,notched=n\\r\\n     7. gill-spacing:             close=c,crowded=w,distant=d\\r\\n     8. gill-size:                broad=b,narrow=n\\r\\n     9. gill-color:               black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y\\r\\n    10. stalk-shape:              enlarging=e,tapering=t\\r\\n    11. stalk-root:               bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?\\r\\n    12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\\r\\n    13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\\r\\n    14. stalk-color-above-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\\r\\n    15. stalk-color-below-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\\r\\n    16. veil-type:                partial=p,universal=u\\r\\n    17. veil-color:               brown=n,orange=o,white=w,yellow=y\\r\\n    18. ring-number:              none=n,one=o,two=t\\r\\n    19. ring-type:                cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z\\r\\n    20. spore-print-color:        black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y\\r\\n    21. population:               abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y\\r\\n    22. habitat:                  grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d',\n",
       "  'citation': None}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mushroom.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cap-shape cap-surface cap-color bruises odor gill-attachment gill-spacing  \\\n",
       "0         x           s         n       t    p               f            c   \n",
       "1         x           s         y       t    a               f            c   \n",
       "2         b           s         w       t    l               f            c   \n",
       "3         x           y         w       t    p               f            c   \n",
       "4         x           s         g       f    n               f            w   \n",
       "\n",
       "  gill-size gill-color stalk-shape  ... stalk-surface-below-ring  \\\n",
       "0         n          k           e  ...                        s   \n",
       "1         b          k           e  ...                        s   \n",
       "2         b          n           e  ...                        s   \n",
       "3         n          n           e  ...                        s   \n",
       "4         b          k           t  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看目标变量分布："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poisonous\n",
       "e            4208\n",
       "p            3916\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **实验过程**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **数据预处理**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "缺失值处理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每列的缺失值数量：\n",
      "cap-shape                      0\n",
      "cap-surface                    0\n",
      "cap-color                      0\n",
      "bruises                        0\n",
      "odor                           0\n",
      "gill-attachment                0\n",
      "gill-spacing                   0\n",
      "gill-size                      0\n",
      "gill-color                     0\n",
      "stalk-shape                    0\n",
      "stalk-root                  2480\n",
      "stalk-surface-above-ring       0\n",
      "stalk-surface-below-ring       0\n",
      "stalk-color-above-ring         0\n",
      "stalk-color-below-ring         0\n",
      "veil-type                      0\n",
      "veil-color                     0\n",
      "ring-number                    0\n",
      "ring-type                      0\n",
      "spore-print-color              0\n",
      "population                     0\n",
      "habitat                        0\n",
      "dtype: int64\n",
      "数据总缺失值数量: 2480\n"
     ]
    }
   ],
   "source": [
    "missing_values = X.isnull().sum()\n",
    "print(\"每列的缺失值数量：\")\n",
    "print(missing_values)\n",
    "\n",
    "total_missing = missing_values.sum()\n",
    "print(f\"数据总缺失值数量: {total_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e' 'c' 'b' 'r' nan]\n",
      "stalk-root\n",
      "b    3776\n",
      "e    1120\n",
      "c     556\n",
      "r     192\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X['stalk-root'].unique())\n",
    "print(X['stalk-root'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过统计可知，缺失值都源自于 stalk-root，该特征描述了蘑菇的根部形态，且缺失值占的比重较大，所以认为缺失值本身包含信息，不对其做删除或填充处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看数据集后发现该数据集中均为非数值数据，因此使用独热编码将分类变量转换为模型可用的数值形式，其作用是将类别型数据表示为二进制特征矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "X_encoded[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分训练集和测试集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **首先调用 python 库查看训练准确率**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "\tAccuracy: 0.9996\n",
      "\tPrecision: 0.9992\n",
      "\tRecall: 1.0000\n",
      "\tF1: 0.9996\n",
      "Decision Tree\n",
      "\tAccuracy: 1.0000\n",
      "\tPrecision: 1.0000\n",
      "\tRecall: 1.0000\n",
      "\tF1: 1.0000\n",
      "Decision Tree\n",
      "\tAccuracy: 1.0000\n",
      "\tPrecision: 1.0000\n",
      "\tRecall: 1.0000\n",
      "\tF1: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\lwc2\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "d:\\miniconda3\\envs\\lwc2\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 训练并评估逻辑回归模型\n",
    "log_reg = LogisticRegression(max_iter=200)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr, pos_label='e')\n",
    "recall_lr = recall_score(y_test,y_pred_lr,pos_label='e')\n",
    "f1_lr = f1_score(y_test,y_pred_lr,pos_label='e')\n",
    "print(f'Logistic Regression\\n\\tAccuracy: {accuracy_lr:.4f}')\n",
    "print(f'\\tPrecision: {precision_lr:.4f}')\n",
    "print(f'\\tRecall: {recall_lr:.4f}')\n",
    "print(f'\\tF1: {f1_lr:.4f}')\n",
    "\n",
    "# 训练并评估决策树模型\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt,pos_label='e')\n",
    "recall_dt = recall_score(y_test,y_pred_dt,pos_label='e')\n",
    "f1_dt = f1_score(y_test,y_pred_dt,pos_label='e')\n",
    "print(f'Decision Tree\\n\\tAccuracy: {accuracy_dt:.4f}')\n",
    "print(f'\\tPrecision: {precision_dt:.4f}')\n",
    "print(f'\\tRecall: {recall_dt:.4f}')\n",
    "print(f'\\tF1: {f1_dt:.4f}')\n",
    "\n",
    "# 训练并评估SVM模型\n",
    "svm = SVC(kernel='linear', gamma='scale', C=1.0, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm,pos_label='e')\n",
    "recall_svm = recall_score(y_test,y_pred_svm,pos_label='e')\n",
    "f1_svm = f1_score(y_test,y_pred_svm,pos_label='e')\n",
    "print(f'Decision Tree\\n\\tAccuracy: {accuracy_svm:.4f}')\n",
    "print(f'\\tPrecision: {precision_svm:.4f}')\n",
    "print(f'\\tRecall: {recall_svm:.4f}')\n",
    "print(f'\\tF1: {f1_svm:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **自己实现 logistic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_logistic = y_train.copy()\n",
    "y_test_logistic = y_test.copy()\n",
    "y_train_logistic['poisonous'] = y_train_logistic['poisonous'].map({'e': 1.0, 'p': 0.0})\n",
    "y_test_logistic['poisonous'] = y_test_logistic['poisonous'].map({'e': 1.0, 'p': 0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/300], Loss: 0.6739, Train Acc: 0.6082\n",
      "Epoch [4/300], Loss: 0.6025, Train Acc: 0.8120\n",
      "Epoch [6/300], Loss: 0.5394, Train Acc: 0.8903\n",
      "Epoch [8/300], Loss: 0.4846, Train Acc: 0.9019\n",
      "Epoch [10/300], Loss: 0.4376, Train Acc: 0.9013\n",
      "Epoch [12/300], Loss: 0.3976, Train Acc: 0.9012\n",
      "Epoch [14/300], Loss: 0.3636, Train Acc: 0.9024\n",
      "Epoch [16/300], Loss: 0.3349, Train Acc: 0.9031\n",
      "Epoch [18/300], Loss: 0.3106, Train Acc: 0.9045\n",
      "Epoch [20/300], Loss: 0.2899, Train Acc: 0.9068\n",
      "Epoch [22/300], Loss: 0.2720, Train Acc: 0.9098\n",
      "Epoch [24/300], Loss: 0.2565, Train Acc: 0.9129\n",
      "Epoch [26/300], Loss: 0.2428, Train Acc: 0.9158\n",
      "Epoch [28/300], Loss: 0.2307, Train Acc: 0.9195\n",
      "Epoch [30/300], Loss: 0.2197, Train Acc: 0.9228\n",
      "Epoch [32/300], Loss: 0.2098, Train Acc: 0.9282\n",
      "Epoch [34/300], Loss: 0.2008, Train Acc: 0.9353\n",
      "Epoch [36/300], Loss: 0.1924, Train Acc: 0.9390\n",
      "Epoch [38/300], Loss: 0.1848, Train Acc: 0.9418\n",
      "Epoch [40/300], Loss: 0.1777, Train Acc: 0.9444\n",
      "Epoch [42/300], Loss: 0.1712, Train Acc: 0.9481\n",
      "Epoch [44/300], Loss: 0.1651, Train Acc: 0.9523\n",
      "Epoch [46/300], Loss: 0.1594, Train Acc: 0.9557\n",
      "Epoch [48/300], Loss: 0.1541, Train Acc: 0.9620\n",
      "Epoch [50/300], Loss: 0.1491, Train Acc: 0.9634\n",
      "Epoch [52/300], Loss: 0.1445, Train Acc: 0.9657\n",
      "Epoch [54/300], Loss: 0.1402, Train Acc: 0.9678\n",
      "Epoch [56/300], Loss: 0.1361, Train Acc: 0.9703\n",
      "Epoch [58/300], Loss: 0.1322, Train Acc: 0.9712\n",
      "Epoch [60/300], Loss: 0.1286, Train Acc: 0.9734\n",
      "Epoch [62/300], Loss: 0.1252, Train Acc: 0.9756\n",
      "Epoch [64/300], Loss: 0.1219, Train Acc: 0.9768\n",
      "Epoch [66/300], Loss: 0.1188, Train Acc: 0.9782\n",
      "Epoch [68/300], Loss: 0.1159, Train Acc: 0.9798\n",
      "Epoch [70/300], Loss: 0.1131, Train Acc: 0.9810\n",
      "Epoch [72/300], Loss: 0.1104, Train Acc: 0.9812\n",
      "Epoch [74/300], Loss: 0.1079, Train Acc: 0.9817\n",
      "Epoch [76/300], Loss: 0.1054, Train Acc: 0.9819\n",
      "Epoch [78/300], Loss: 0.1031, Train Acc: 0.9822\n",
      "Epoch [80/300], Loss: 0.1008, Train Acc: 0.9829\n",
      "Epoch [82/300], Loss: 0.0987, Train Acc: 0.9833\n",
      "Epoch [84/300], Loss: 0.0966, Train Acc: 0.9838\n",
      "Epoch [86/300], Loss: 0.0947, Train Acc: 0.9843\n",
      "Epoch [88/300], Loss: 0.0928, Train Acc: 0.9858\n",
      "Epoch [90/300], Loss: 0.0909, Train Acc: 0.9863\n",
      "Epoch [92/300], Loss: 0.0891, Train Acc: 0.9865\n",
      "Epoch [94/300], Loss: 0.0874, Train Acc: 0.9870\n",
      "Epoch [96/300], Loss: 0.0858, Train Acc: 0.9872\n",
      "Epoch [98/300], Loss: 0.0842, Train Acc: 0.9875\n",
      "Epoch [100/300], Loss: 0.0827, Train Acc: 0.9879\n",
      "Epoch [102/300], Loss: 0.0812, Train Acc: 0.9879\n",
      "Epoch [104/300], Loss: 0.0798, Train Acc: 0.9880\n",
      "Epoch [106/300], Loss: 0.0784, Train Acc: 0.9882\n",
      "Epoch [108/300], Loss: 0.0770, Train Acc: 0.9886\n",
      "Epoch [110/300], Loss: 0.0757, Train Acc: 0.9891\n",
      "Epoch [112/300], Loss: 0.0744, Train Acc: 0.9894\n",
      "Epoch [114/300], Loss: 0.0732, Train Acc: 0.9900\n",
      "Epoch [116/300], Loss: 0.0720, Train Acc: 0.9900\n",
      "Epoch [118/300], Loss: 0.0709, Train Acc: 0.9902\n",
      "Epoch [120/300], Loss: 0.0698, Train Acc: 0.9902\n",
      "Epoch [122/300], Loss: 0.0687, Train Acc: 0.9905\n",
      "Epoch [124/300], Loss: 0.0676, Train Acc: 0.9910\n",
      "Epoch [126/300], Loss: 0.0666, Train Acc: 0.9910\n",
      "Epoch [128/300], Loss: 0.0656, Train Acc: 0.9910\n",
      "Epoch [130/300], Loss: 0.0646, Train Acc: 0.9912\n",
      "Epoch [132/300], Loss: 0.0636, Train Acc: 0.9916\n",
      "Epoch [134/300], Loss: 0.0627, Train Acc: 0.9916\n",
      "Epoch [136/300], Loss: 0.0618, Train Acc: 0.9919\n",
      "Epoch [138/300], Loss: 0.0609, Train Acc: 0.9923\n",
      "Epoch [140/300], Loss: 0.0601, Train Acc: 0.9928\n",
      "Epoch [142/300], Loss: 0.0592, Train Acc: 0.9930\n",
      "Epoch [144/300], Loss: 0.0584, Train Acc: 0.9935\n",
      "Epoch [146/300], Loss: 0.0576, Train Acc: 0.9935\n",
      "Epoch [148/300], Loss: 0.0569, Train Acc: 0.9938\n",
      "Epoch [150/300], Loss: 0.0561, Train Acc: 0.9938\n",
      "Epoch [152/300], Loss: 0.0554, Train Acc: 0.9940\n",
      "Epoch [154/300], Loss: 0.0546, Train Acc: 0.9944\n",
      "Epoch [156/300], Loss: 0.0539, Train Acc: 0.9945\n",
      "Epoch [158/300], Loss: 0.0532, Train Acc: 0.9945\n",
      "Epoch [160/300], Loss: 0.0526, Train Acc: 0.9945\n",
      "Epoch [162/300], Loss: 0.0519, Train Acc: 0.9945\n",
      "Epoch [164/300], Loss: 0.0513, Train Acc: 0.9945\n",
      "Epoch [166/300], Loss: 0.0506, Train Acc: 0.9945\n",
      "Epoch [168/300], Loss: 0.0500, Train Acc: 0.9945\n",
      "Epoch [170/300], Loss: 0.0494, Train Acc: 0.9945\n",
      "Epoch [172/300], Loss: 0.0488, Train Acc: 0.9947\n",
      "Epoch [174/300], Loss: 0.0482, Train Acc: 0.9947\n",
      "Epoch [176/300], Loss: 0.0477, Train Acc: 0.9953\n",
      "Epoch [178/300], Loss: 0.0471, Train Acc: 0.9954\n",
      "Epoch [180/300], Loss: 0.0466, Train Acc: 0.9954\n",
      "Epoch [182/300], Loss: 0.0460, Train Acc: 0.9956\n",
      "Epoch [184/300], Loss: 0.0455, Train Acc: 0.9956\n",
      "Epoch [186/300], Loss: 0.0450, Train Acc: 0.9958\n",
      "Epoch [188/300], Loss: 0.0445, Train Acc: 0.9961\n",
      "Epoch [190/300], Loss: 0.0440, Train Acc: 0.9963\n",
      "Epoch [192/300], Loss: 0.0435, Train Acc: 0.9963\n",
      "Epoch [194/300], Loss: 0.0430, Train Acc: 0.9963\n",
      "Epoch [196/300], Loss: 0.0426, Train Acc: 0.9963\n",
      "Epoch [198/300], Loss: 0.0421, Train Acc: 0.9967\n",
      "Epoch [200/300], Loss: 0.0417, Train Acc: 0.9967\n",
      "Epoch [202/300], Loss: 0.0412, Train Acc: 0.9967\n",
      "Epoch [204/300], Loss: 0.0408, Train Acc: 0.9967\n",
      "Epoch [206/300], Loss: 0.0404, Train Acc: 0.9970\n",
      "Epoch [208/300], Loss: 0.0399, Train Acc: 0.9970\n",
      "Epoch [210/300], Loss: 0.0395, Train Acc: 0.9972\n",
      "Epoch [212/300], Loss: 0.0391, Train Acc: 0.9972\n",
      "Epoch [214/300], Loss: 0.0387, Train Acc: 0.9972\n",
      "Epoch [216/300], Loss: 0.0383, Train Acc: 0.9972\n",
      "Epoch [218/300], Loss: 0.0380, Train Acc: 0.9972\n",
      "Epoch [220/300], Loss: 0.0376, Train Acc: 0.9972\n",
      "Epoch [222/300], Loss: 0.0372, Train Acc: 0.9972\n",
      "Epoch [224/300], Loss: 0.0369, Train Acc: 0.9974\n",
      "Epoch [226/300], Loss: 0.0365, Train Acc: 0.9974\n",
      "Epoch [228/300], Loss: 0.0361, Train Acc: 0.9974\n",
      "Epoch [230/300], Loss: 0.0358, Train Acc: 0.9974\n",
      "Epoch [232/300], Loss: 0.0355, Train Acc: 0.9974\n",
      "Epoch [234/300], Loss: 0.0351, Train Acc: 0.9974\n",
      "Epoch [236/300], Loss: 0.0348, Train Acc: 0.9974\n",
      "Epoch [238/300], Loss: 0.0345, Train Acc: 0.9974\n",
      "Epoch [240/300], Loss: 0.0342, Train Acc: 0.9974\n",
      "Epoch [242/300], Loss: 0.0338, Train Acc: 0.9974\n",
      "Epoch [244/300], Loss: 0.0335, Train Acc: 0.9974\n",
      "Epoch [246/300], Loss: 0.0332, Train Acc: 0.9974\n",
      "Epoch [248/300], Loss: 0.0329, Train Acc: 0.9974\n",
      "Epoch [250/300], Loss: 0.0326, Train Acc: 0.9974\n",
      "Epoch [252/300], Loss: 0.0323, Train Acc: 0.9975\n",
      "Epoch [254/300], Loss: 0.0321, Train Acc: 0.9975\n",
      "Epoch [256/300], Loss: 0.0318, Train Acc: 0.9975\n",
      "Epoch [258/300], Loss: 0.0315, Train Acc: 0.9975\n",
      "Epoch [260/300], Loss: 0.0312, Train Acc: 0.9975\n",
      "Epoch [262/300], Loss: 0.0310, Train Acc: 0.9977\n",
      "Epoch [264/300], Loss: 0.0307, Train Acc: 0.9979\n",
      "Epoch [266/300], Loss: 0.0304, Train Acc: 0.9979\n",
      "Epoch [268/300], Loss: 0.0302, Train Acc: 0.9979\n",
      "Epoch [270/300], Loss: 0.0299, Train Acc: 0.9979\n",
      "Epoch [272/300], Loss: 0.0297, Train Acc: 0.9979\n",
      "Epoch [274/300], Loss: 0.0294, Train Acc: 0.9979\n",
      "Epoch [276/300], Loss: 0.0292, Train Acc: 0.9979\n",
      "Epoch [278/300], Loss: 0.0289, Train Acc: 0.9979\n",
      "Epoch [280/300], Loss: 0.0287, Train Acc: 0.9981\n",
      "Epoch [282/300], Loss: 0.0285, Train Acc: 0.9982\n",
      "Epoch [284/300], Loss: 0.0282, Train Acc: 0.9982\n",
      "Epoch [286/300], Loss: 0.0280, Train Acc: 0.9984\n",
      "Epoch [288/300], Loss: 0.0278, Train Acc: 0.9984\n",
      "Epoch [290/300], Loss: 0.0276, Train Acc: 0.9984\n",
      "Epoch [292/300], Loss: 0.0273, Train Acc: 0.9986\n",
      "Epoch [294/300], Loss: 0.0271, Train Acc: 0.9986\n",
      "Epoch [296/300], Loss: 0.0269, Train Acc: 0.9986\n",
      "Epoch [298/300], Loss: 0.0267, Train Acc: 0.9986\n",
      "Epoch [300/300], Loss: 0.0265, Train Acc: 0.9988\n",
      "Test Accuracy: 0.9988\n",
      "Test Precision: 0.9984\n",
      "Test Recall: 0.9992\n",
      "Test F1: 0.9988\n"
     ]
    }
   ],
   "source": [
    "# 转换为PyTorch张量\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train_logistic.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test_logistic.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 逻辑回归 = Linear + Sigmoid\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train_t.shape[1], 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 训练模型\n",
    "epochs = 300\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train_t)\n",
    "    loss = criterion(y_pred, y_train_t)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 简单监控训练过程\n",
    "    if (epoch+1) % 2 == 0:\n",
    "        with torch.no_grad():\n",
    "            # 计算训练集准确率\n",
    "            train_pred = (y_pred > 0.5).float()\n",
    "            train_acc = (train_pred == y_train_t).float().mean().item()\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Train Acc: {train_acc:.4f}')\n",
    "\n",
    "# 测试模型\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_t)\n",
    "    test_pred = (y_test_pred > 0.5).float()\n",
    "    # test_acc = (test_pred == y_test_t).float().mean().item()\n",
    "    test_acc = accuracy_score(y_test_t, test_pred)\n",
    "    test_prec = precision_score(y_test_t, test_pred)\n",
    "    test_rec = recall_score(y_test_t, test_pred)\n",
    "    test_f1 = f1_score(y_test_t, test_pred)\n",
    "\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "print(f'Test Precision: {test_prec:.4f}')\n",
    "print(f'Test Recall: {test_rec:.4f}')\n",
    "print(f'Test F1: {test_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tree = (y_train_logistic.values).ravel()\n",
    "y_test_tree = (y_test_logistic.values).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5686,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_tree.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **自己实现决策树**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0000\n",
      "Test Precision: 1.0000\n",
      "Test Recall: 1.0000\n",
      "Test F1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def entropy(labels):\n",
    "    from math import log2\n",
    "    counts = {}\n",
    "    for l in labels:\n",
    "        counts[l] = counts.get(l, 0) + 1\n",
    "    total = len(labels)\n",
    "    ent = 0.0\n",
    "    for c in counts.values():\n",
    "        p = c/total\n",
    "        ent -= p * log2(p)\n",
    "    return ent\n",
    "\n",
    "def information_gain(X, y, feature_index):\n",
    "    base_entropy = entropy(y)\n",
    "    values = X[:, feature_index]\n",
    "    unique_vals = np.unique(values)\n",
    "    new_entropy = 0.0\n",
    "    total = len(y)\n",
    "    for val in unique_vals:\n",
    "        subset_y = y[values == val]\n",
    "        prob = len(subset_y) / total\n",
    "        new_entropy += prob * entropy(subset_y)\n",
    "    return base_entropy - new_entropy\n",
    "\n",
    "def majority_class(labels):\n",
    "    from collections import Counter\n",
    "    counter = Counter(labels)\n",
    "    return counter.most_common(1)[0][0]\n",
    "\n",
    "# 递归构建决策树\n",
    "def build_tree(X, y, feature_indices):\n",
    "    # 如果所有标签相同，直接返回该标签\n",
    "    if len(set(y)) == 1:\n",
    "        return y[0]\n",
    "    \n",
    "    if len(feature_indices) == 0:\n",
    "        # 无特征可分时，返回多数类\n",
    "        return majority_class(y)\n",
    "    \n",
    "    # 选择信息增益最大特征\n",
    "    gains = [information_gain(X, y, fi) for fi in feature_indices]\n",
    "    best_feature = feature_indices[np.argmax(gains)]\n",
    "    \n",
    "    # 如果信息增益为0，无法继续分割，返回多数类\n",
    "    if max(gains) == 0:\n",
    "        return majority_class(y)\n",
    "    \n",
    "    tree = {best_feature: {}}\n",
    "    values = X[:, best_feature]\n",
    "    unique_vals = np.unique(values)\n",
    "    # 子集划分\n",
    "    new_feature_indices = [fi for fi in feature_indices if fi != best_feature]\n",
    "    for val in unique_vals:\n",
    "        subset_mask = (values == val)\n",
    "        subtree = build_tree(X[subset_mask], y[subset_mask], new_feature_indices)\n",
    "        tree[best_feature][val] = subtree\n",
    "    return tree\n",
    "\n",
    "def tree_predict(tree, x):\n",
    "    if not isinstance(tree, dict):\n",
    "        # 叶节点\n",
    "        return tree\n",
    "    # tree结构: {feature_index: {value: subtree, ...}}\n",
    "    feature_index = list(tree.keys())[0]\n",
    "    feature_val = x[feature_index]\n",
    "    branches = tree[feature_index]\n",
    "    if feature_val in branches:\n",
    "        return tree_predict(branches[feature_val], x)\n",
    "    else:\n",
    "        # 如果没有对应分支，返回多数类策略\n",
    "        # 或随机选一个分支，这里简单返回多数类策略\n",
    "        # 不严谨，但作为演示\n",
    "        return majority_class(list(branches.values()))\n",
    "\n",
    "# 构建决策树\n",
    "feature_indices = list(range(X_train.shape[1]))\n",
    "decision_tree = build_tree(X_train, y_train_tree, feature_indices)\n",
    "\n",
    "# 决策树预测与精度\n",
    "dt_preds = [tree_predict(decision_tree, x) for x in X_test]\n",
    "\n",
    "test_acc = accuracy_score(y_test_tree, dt_preds)\n",
    "test_prec = precision_score(y_test_tree, dt_preds)\n",
    "test_rec = recall_score(y_test_tree, dt_preds)\n",
    "test_f1 = f1_score(y_test_tree, dt_preds)\n",
    "\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "print(f'Test Precision: {test_prec:.4f}')\n",
    "print(f'Test Recall: {test_rec:.4f}')\n",
    "print(f'Test F1: {test_f1:.4f}')\n",
    "#dt_accuracy = np.mean(dt_preds == y_test_tree)\n",
    "#print(f\"Decision Tree Accuracy: {dt_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **自己实现 SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_SVM = y_train_tree.copy()\n",
    "y_test_SVM = y_test_tree.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (5686, 117)\n",
      "y_train_SVM shape: (5686,)\n"
     ]
    }
   ],
   "source": [
    "# 检查标准化或缩放过程\n",
    "print(f\"X_train_scaled shape: {X_train.shape}\")\n",
    "print(f\"y_train_SVM shape: {y_train_SVM.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 286.7653\n",
      "Epoch 2/20, Loss: 284.4900\n",
      "Epoch 3/20, Loss: 290.6429\n",
      "Epoch 4/20, Loss: 294.0821\n",
      "Epoch 5/20, Loss: 278.3218\n",
      "Epoch 6/20, Loss: 280.7040\n",
      "Epoch 7/20, Loss: 277.2778\n",
      "Epoch 8/20, Loss: 289.7039\n",
      "Epoch 9/20, Loss: 278.0973\n",
      "Epoch 10/20, Loss: 288.2401\n",
      "Epoch 11/20, Loss: 277.3806\n",
      "Epoch 12/20, Loss: 280.3890\n",
      "Epoch 13/20, Loss: 278.7140\n",
      "Epoch 14/20, Loss: 278.8103\n",
      "Epoch 15/20, Loss: 276.1944\n",
      "Epoch 16/20, Loss: 275.0444\n",
      "Epoch 17/20, Loss: 273.3098\n",
      "Epoch 18/20, Loss: 276.3710\n",
      "Epoch 19/20, Loss: 281.3475\n",
      "Epoch 20/20, Loss: 278.3885\n",
      "Test Accuracy: 0.9963\n",
      "Test Precision: 0.9928\n",
      "Test Recall: 1.0000\n",
      "Test F1: 0.9964\n"
     ]
    }
   ],
   "source": [
    "# 使用次梯度下降实现线性SVM\n",
    "# C: 正则化参数 \n",
    "# decay_rate: 学习率衰减率\n",
    "def linear_svm_train(X, y, C=1.0, lr=0.001, epochs=10, decay_rate=0.01):\n",
    "    N, d = X.shape\n",
    "    w = np.zeros(d)\n",
    "    b = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(N):\n",
    "            # 检查是否满足间隔条件 y_i * (w·x_i + b) >= 1\n",
    "            if y[i] * (np.dot(w, X[i]) + b) < 1:\n",
    "                # 不满足条件，更新 w 和 b\n",
    "                w = w - lr * (w - C * y[i] * X[i])\n",
    "                b = b + lr * C * y[i]\n",
    "            else:\n",
    "                # 满足条件，只更新 w\n",
    "                w = w - lr * w\n",
    "\n",
    "        # 动态调整学习率\n",
    "        lr = lr / (1 + epoch * decay_rate)\n",
    "\n",
    "        # 可选：打印每轮损失值\n",
    "        hinge_loss = np.maximum(0, 1 - y * (np.dot(X, w) + b)).sum()\n",
    "        total_loss = 0.5 * np.dot(w, w) + C * hinge_loss\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    return w, b\n",
    "\n",
    "def linear_svm_predict(X, w, b):\n",
    "    return np.sign(np.dot(X, w) + b)\n",
    "\n",
    "# 数据标准化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 确保标签为 {-1, 1}\n",
    "y_train_SVM = np.where(y_train_SVM == 0, -1, y_train_SVM)\n",
    "y_test_SVM = np.where(y_test_SVM == 0, -1, y_test_SVM)\n",
    "\n",
    "# print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
    "# print(f\"y_train_SVM shape: {y_train_SVM.shape}\")\n",
    "\n",
    "# 训练线性 SVM\n",
    "w_svm, b_svm = linear_svm_train(X_train_scaled, y_train_SVM, C=1.0, lr=0.001, epochs=20)\n",
    "\n",
    "# 预测并计算准确率\n",
    "svm_preds = linear_svm_predict(X_test_scaled, w_svm, b_svm)\n",
    "\n",
    "test_acc = accuracy_score(y_test_SVM, svm_preds)\n",
    "test_prec = precision_score(y_test_SVM, svm_preds)\n",
    "test_rec = recall_score(y_test_SVM, svm_preds)\n",
    "test_f1 = f1_score(y_test_SVM, svm_preds)\n",
    "\n",
    "print(f'Test Accuracy: {test_acc:.4f}')\n",
    "print(f'Test Precision: {test_prec:.4f}')\n",
    "print(f'Test Recall: {test_rec:.4f}')\n",
    "print(f'Test F1: {test_f1:.4f}')\n",
    "\n",
    "#svm_accuracy = np.mean(svm_preds == y_test_SVM)\n",
    "#print(f\"SVM Accuracy: {svm_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lwc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
